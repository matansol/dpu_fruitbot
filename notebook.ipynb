{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d99c3188",
   "metadata": {},
   "source": [
    "### To build the procgen\n",
    "in terminal:\n",
    "python -c \"from procgen.builder import build; build()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b58610be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
      "c:\\Users\\matan\\anaconda3\\envs\\rl_env\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\rl_env\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\rl_env\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'numpy.ndarray'>`\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\rl_env\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:219: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\rl_env\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:225: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(done, (bool, np.bool8)):\n",
      "c:\\Users\\matan\\anaconda3\\envs\\rl_env\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\rl_env\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\rl_env\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'numpy.ndarray'>`\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\rl_env\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:219: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\rl_env\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:225: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(done, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viewer started; close the window or press Ctrl+C to stop\n",
      "action space Discrete(4)\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import gym, time, procgen\n",
    "from wrappers import make_fruitbot_basic\n",
    "\n",
    "env=gym.make('procgen:procgen-fruitbot-v0', render_mode='human')\n",
    "env = make_fruitbot_basic(env)\n",
    "obs=env.reset()\n",
    "print('viewer started; close the window or press Ctrl+C to stop')\n",
    "import itertools\n",
    "print(\"action space\", env.action_space)\n",
    "for i in range(100):\n",
    "    action = env.action_space.sample()\n",
    "    # Handle both gym (4 values) and gymnasium (5 values) API\n",
    "    obs, rew, done, truncated, info = env.step(action)\n",
    "    if done: obs = env.reset()\n",
    "    time.sleep(0.05)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4875809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building procgen...done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matan\\anaconda3\\envs\\rl_env\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\rl_env\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\rl_env\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'numpy.ndarray'>`\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\rl_env\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:219: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "c:\\Users\\matan\\anaconda3\\envs\\rl_env\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:225: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(done, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not found at models/fruitbot/20251117-133701/ppo_final.zip. Falling back to random actions.\n",
      "Run finished\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load a trained PPO model and run it on the existing `env`.\n",
    "# If the model file is missing, fall back to random actions.\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "import gym, time, procgen\n",
    "from wrappers import make_fruitbot_basic\n",
    "\n",
    "model_path = \"models/fruitbot/20251117-133701/ppo_final.zip\"\n",
    "\n",
    "# Control which level to test on\n",
    "START_LEVEL = 0  # Change this to test different levels (0, 1, 2, ...)\n",
    "NUM_LEVELS = 1   # Set to 1 for single level, 10 for training set, 0 for random\n",
    "\n",
    "env = gym.make('procgen:procgen-fruitbot-v0', \n",
    "               render_mode='human', \n",
    "               distribution_mode='easy',\n",
    "               )\n",
    "env = make_fruitbot_basic(env)\n",
    "obs = env.reset()\n",
    "if os.path.exists(model_path):\n",
    "    model = PPO.load(model_path, env=env)\n",
    "    print(f\"Loaded PPO model from {model_path}\")\n",
    "else:\n",
    "    model = None\n",
    "    print(f\"Model not found at {model_path}. Falling back to random actions.\")\n",
    "\n",
    "\n",
    "# Run for a number of steps (or until user closes the viewer)\n",
    "max_steps = 200\n",
    "for step in range(max_steps):\n",
    "    if model is not None:\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "    else:\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "    result = env.step(action)\n",
    "    # handle both gym (obs, rew, done, info) and gymnasium (obs, rew, done, truncated, info)\n",
    "    if len(result) == 5:\n",
    "        obs, rew, done, truncated, info = result\n",
    "    else:\n",
    "        obs, rew, done, info = result\n",
    "        truncated = False\n",
    "\n",
    "    if done or truncated:\n",
    "        obs = env.reset()\n",
    "\n",
    "    # small delay so human viewer can follow\n",
    "    time.sleep(0.02)\n",
    "\n",
    "print(\"Run finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea699b8",
   "metadata": {},
   "source": [
    "## CNN architecuter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76c63c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FULL ACTOR-CRITIC NETWORK\n",
      "============================================================\n",
      "ActorCriticCnnPolicy(\n",
      "  (features_extractor): NatureCNN(\n",
      "    (cnn): Sequential(\n",
      "      (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (linear): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (pi_features_extractor): NatureCNN(\n",
      "    (cnn): Sequential(\n",
      "      (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (linear): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (vf_features_extractor): NatureCNN(\n",
      "    (cnn): Sequential(\n",
      "      (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (linear): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (mlp_extractor): MlpExtractor(\n",
      "    (policy_net): Sequential()\n",
      "    (value_net): Sequential()\n",
      "  )\n",
      "  (action_net): Linear(in_features=512, out_features=4, bias=True)\n",
      "  (value_net): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "============================================================\n",
      "PARAMETER COUNT\n",
      "============================================================\n",
      "Feature extractor: 600,736 params\n",
      "Actor head: 2,052 params\n",
      "Critic head: 513 params\n",
      "Total: 603,301 params\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import torch\n",
    "\n",
    "# Load your trained model\n",
    "model = PPO.load(\"models/fruitbot/20251117-143015/ppo_final.zip\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FULL ACTOR-CRITIC NETWORK\")\n",
    "print(\"=\"*60)\n",
    "print(model.policy)\n",
    "\n",
    "\n",
    "# Count parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PARAMETER COUNT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Feature extractor: {count_parameters(model.policy.features_extractor):,} params\")\n",
    "print(f\"Actor head: {count_parameters(model.policy.action_net):,} params\")\n",
    "print(f\"Critic head: {count_parameters(model.policy.value_net):,} params\")\n",
    "print(f\"Total: {count_parameters(model.policy):,} params\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
